{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import sparksession, Q, QClust\n",
    "from context import GeneticRangeAnalysis, MSSelector, RangeAnalysis, GA, BranchAndBound, FitnessUtils, DeCaf\n",
    "from sklearn.cluster import KMeans, MeanShift, AgglomerativeClustering\n",
    "from operator import itemgetter\n",
    "import time\n",
    "from math import log2\n",
    "import random\n",
    "import numpy as np\n",
    "from deap.tools import sortNondominated\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import multiprocessing\n",
    "from sklearn.cluster import estimate_bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontend = 'HomeControllerHome'\n",
    "get_rpcs = lambda traces: [c for c in traces.columns if c != 'traceId' and c != 'experiment' and c != frontend]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparksession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kclustering(traces, sla, Clustering):\n",
    "    rpcs = get_rpcs(traces)\n",
    "    anomalytraces = traces[traces[frontend]>sla]\n",
    "    dflist = []\n",
    "    for k in range(2, 11):\n",
    "        df = anomalytraces.select(['experiment', 'traceId'] + rpcs).toPandas()\n",
    "        clust = Clustering(k)\n",
    "        df['pred'] = clust.fit_predict(df[rpcs])\n",
    "        dflist.append(df)\n",
    "    return dflist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical(traces, sla):\n",
    "    return kclustering(traces, sla, AgglomerativeClustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(traces, sla):\n",
    "    return kclustering(traces, sla, KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanshift(traces, sla):\n",
    "    anomalytraces = traces[traces[frontend]>sla]\n",
    "    rpcs = get_rpcs(traces)\n",
    "    df = anomalytraces.select(['experiment', 'traceId'] + rpcs).toPandas()\n",
    "    clust = MeanShift(5)\n",
    "    df['pred'] = clust.fit_predict(df[rpcs])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_based(traces, sla, explain):\n",
    "    anomalytraces = traces[traces[frontend]>sla]\n",
    "    min_bin_freq = anomalytraces.count()*0.05\n",
    "    bandwidth =  estimate_bandwidth(traces.toPandas()[[frontend]], quantile=0.1)\n",
    "\n",
    "    mss = MSSelector(anomalytraces, bandwidth=bandwidth, min_bin_freq=min_bin_freq)\n",
    "    split_points = mss.select(frontend)\n",
    "\n",
    "    ra = RangeAnalysis(explain, split_points)\n",
    "    _, _, solutions = ra.explain()\n",
    "    \n",
    "    return list(map(itemgetter(0), solutions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholdsdict(traces):\n",
    "    anomalytraces = traces[traces[frontend]>sla]\n",
    "    min_bin_freq = anomalytraces.count()*0.05\n",
    "    rpcs = get_rpcs(traces)\n",
    "    mss = MSSelector(traces, min_bin_freq=min_bin_freq)\n",
    "    return mss.select_foreach(rpcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ga(traces, sla):\n",
    "    td = thresholdsdict(traces)\n",
    "    rpcs = get_rpcs(traces)\n",
    "    explain = GA(traces, rpcs, frontend, td).compute\n",
    "    return split_based(traces, sla, explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bnb(traces, sla):\n",
    "    td = thresholdsdict(traces)\n",
    "    explain = BranchAndBound(traces, frontend, td).compute\n",
    "    return split_based(traces, sla, explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decaf(traces, sla):\n",
    "    rpcs = get_rpcs(traces)\n",
    "    dc = DeCaf(traces, frontend, rpcs,sla)\n",
    "    return dc.explain(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gra(traces, sla):\n",
    "    td = thresholdsdict(traces)\n",
    "    max_ = traces.select(frontend).rdd.max()[0]\n",
    "    gra = GeneticRangeAnalysis(traces, frontend, td, sla, max_)\n",
    "    pareto, _ = gra.explain(ngen=300, mu=30, lambda_=30)\n",
    "    best = gra.best(pareto)\n",
    "    print(\"Pareto size\", len(pareto))\n",
    "    print('Best sol fitnesses', best.fitness.values)\n",
    "    print('Best sol number of patterns', len(best))\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qopt(traces, rpcs, num_pat, res):\n",
    "    q = Q(traces, rpcs, num_pat, res)\n",
    "    return q.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qclust(traces, rpcs, num_pat, df):\n",
    "    q = QClust(df, num_pat)\n",
    "    return q.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qkclust(traces, rpcs, num_pat, dflist):\n",
    "    qs =[ qclust(traces, rpcs, num_pat, df) for df in dflist]\n",
    "    return max(qs, key=itemgetter(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(algo, q, traces, num_pat):\n",
    "    rpcs = get_rpcs(traces)\n",
    "    sla = traces[traces['experiment']<num_pat].toPandas().min()[frontend]\n",
    "    \n",
    "    t1 = time.perf_counter()\n",
    "    \n",
    "    res = algo(traces, sla)\n",
    "    \n",
    "    t2 = time.perf_counter()\n",
    "    \n",
    "    fm, prec, rec = q(traces, rpcs, num_pat, res)\n",
    "    t = t2 - t1\n",
    "    return fm, prec, rec, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rep = 20\n",
    "algorithms =[(\"gra\", gra, qopt, num_rep),\n",
    "             (\"ga\", ga, qopt, num_rep),\n",
    "             (\"bnb\", bnb, qopt, 1),\n",
    "             (\"decaf\", decaf, qopt, num_rep),\n",
    "             (\"kmeans\", kmeans, qkclust, num_rep),\n",
    "             (\"hierarchical\", hierarchical, qkclust, num_rep)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (20, 15)\n",
    "\n",
    "\n",
    "datapath = '../data_/cococcia_rq1/'\n",
    "respath = '../results_last/cococcia_rq1.csv'\n",
    "res = []\n",
    "exps = pd.read_csv( datapath+'/experiments.csv', ';', header=None)\n",
    "for row in exps.iterrows():\n",
    "    num_pat, from_, to =[int(x) for x in row[1]]\n",
    "    traces = (spark.read.option('mergeSchema', 'true')\n",
    "              .parquet(datapath+'/%d_%d.parquet' % (from_, to)))\n",
    "\n",
    "    print(traces.count())\n",
    "    sla = traces[traces['experiment'] < num_pat].toPandas().min()[frontend]\n",
    "    for name, algo, q, num_rep in algorithms:\n",
    "        random.seed(33)\n",
    "        np.random.seed(33)\n",
    "        for j in range(num_rep):\n",
    "            print('Algorithm ', name)\n",
    "            print('Experiment nr.', row[0])\n",
    "            fm, prec, rec, t = experiment(algo, q, traces, num_pat)\n",
    "            print('Quality: ', fm, prec, rec)\n",
    "            print('Execution time', t, '\\n\\n\\n')            \n",
    "            res.append([row[0], j, num_pat, name, fm, prec, rec, t])\n",
    "df = pd.DataFrame(res, columns=['exp','trial','num_pat', 'algo','fmeasure', 'precision', 'recall', 'time' ])\n",
    "df.to_csv(respath, index = None, header=True)\n",
    "sns.barplot(x='algo', y='fmeasure', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
